"""
Utility functions for retrosynthesis evaluation
"""
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple


def normalize_smiles(smiles: str) -> str:
    """
    æ ‡å‡†åŒ– SMILES å­—ç¬¦ä¸²ï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…
    å°†ç‚¹å·åˆ†éš”çš„ååº”ç‰©æ’åºï¼Œä»¥å¿½ç•¥ååº”ç‰©é¡ºåºå·®å¼‚
    
    Args:
        smiles: SMILES å­—ç¬¦ä¸²ï¼Œå¯èƒ½åŒ…å«å¤šä¸ªååº”ç‰©ï¼ˆç”¨ç‚¹å·åˆ†éš”ï¼‰
    
    Returns:
        æ ‡å‡†åŒ–åçš„ SMILES å­—ç¬¦ä¸²ï¼ˆååº”ç‰©æŒ‰å­—å…¸åºæ’åºï¼‰
    
    Example:
        >>> normalize_smiles("CCO.CC(=O)Cl")
        "CC(=O)Cl.CCO"
    """
    if not smiles:
        return ""
    
    # å»é™¤é¦–å°¾ç©ºæ ¼
    smiles = smiles.strip()
    
    # åˆ†å‰²ç‚¹å·åˆ†éš”çš„ SMILES
    parts = smiles.split('.')
    
    # å»é™¤æ¯ä¸ªéƒ¨åˆ†çš„ç©ºæ ¼å¹¶æ’åº
    parts = [part.strip() for part in parts if part.strip()]
    parts.sort()
    
    # é‡æ–°ç»„åˆ
    return '.'.join(parts)


def extract_answer_from_result_file(file_path: str) -> Tuple[str, str, bool]:
    """
    ä»ç»“æœæ–‡ä»¶ä¸­æå–é¢„æµ‹ç­”æ¡ˆã€æ­£ç¡®ç­”æ¡ˆå’ŒåŸå§‹åˆ¤æ–­ç»“æœ
    
    Args:
        file_path: ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ results/llm_retro_claude/1.txtï¼‰
    
    Returns:
        (predicted_answer, correct_answer, original_passed) å…ƒç»„
    
    Example file format:
        ...
        Final Answer:CC(=O)Cl.c1ccc2c(ccn2C(=O)OC(C)(C)C)c1
        
        Correct Answer:
        CC(=O)c1ccc2[nH]ccc2c1.CC(C)(C)OC(=O)OC(=O)OC(C)(C)C
        
        Passed:
        False
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– Final Answer
    final_answer_pattern = r'Final Answer:\s*([^\n]+)'
    final_match = re.search(final_answer_pattern, content)
    predicted = final_match.group(1).strip() if final_match else None
    
    # æå– Correct Answer
    correct_answer_pattern = r'Correct Answer:\s*([^\n]+)'
    correct_match = re.search(correct_answer_pattern, content)
    correct = correct_match.group(1).strip() if correct_match else None
    
    # æå–åŸå§‹ Passed ç»“æœ
    passed_pattern = r'Passed:\s*(True|False)'
    passed_match = re.search(passed_pattern, content)
    original_passed = passed_match.group(1) == "True" if passed_match else False
    
    return predicted, correct, original_passed


def fuzzy_match_smiles(predicted: str, correct: str) -> bool:
    """
    æ¨¡ç³ŠåŒ¹é…ä¸¤ä¸ª SMILES å­—ç¬¦ä¸²ï¼Œå¿½ç•¥ååº”ç‰©é¡ºåº
    
    Args:
        predicted: é¢„æµ‹çš„ SMILES å­—ç¬¦ä¸²
        correct: æ­£ç¡®çš„ SMILES å­—ç¬¦ä¸²
    
    Returns:
        æ˜¯å¦åŒ¹é…ï¼ˆTrue/Falseï¼‰
    
    Example:
        >>> fuzzy_match_smiles("CCO.CC(=O)Cl", "CC(=O)Cl.CCO")
        True
    """
    if predicted is None or correct is None:
        return False
    
    # æ ‡å‡†åŒ–å¹¶æ¯”è¾ƒ
    norm_pred = normalize_smiles(predicted)
    norm_correct = normalize_smiles(correct)
    
    return norm_pred == norm_correct


def evaluate_retro_results_fuzzy(results_dir: str, verbose: bool = True) -> Dict:
    """
    å¯¹é€†åˆæˆç»“æœæ–‡ä»¶å¤¹è¿›è¡Œæ¨¡ç³ŠåŒ¹é…è¯„ä¼°
    å¿½ç•¥ååº”ç‰©é¡ºåºå·®å¼‚ï¼Œè¿”å›çœŸæ­£çš„å‡†ç¡®ç‡
    
    Args:
        results_dir: ç»“æœæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¦‚ "results/llm_retro_claude"ï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
        - total: æ€»æ ·æœ¬æ•°
        - strict_correct: ä¸¥æ ¼åŒ¹é…æ­£ç¡®æ•°
        - fuzzy_correct: æ¨¡ç³ŠåŒ¹é…æ­£ç¡®æ•°
        - strict_accuracy: ä¸¥æ ¼åŒ¹é…å‡†ç¡®ç‡
        - fuzzy_accuracy: æ¨¡ç³ŠåŒ¹é…å‡†ç¡®ç‡
        - improved_count: æ¨¡ç³ŠåŒ¹é…é¢å¤–çº æ­£çš„æ ·æœ¬æ•°
        - details: æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†ç»“æœåˆ—è¡¨
    
    Example:
        >>> results = evaluate_retro_results_fuzzy("results/llm_retro_claude")
        >>> print(f"Fuzzy Accuracy: {results['fuzzy_accuracy']:.2%}")
    """
    results_path = Path(results_dir)
    
    if not results_path.exists():
        raise ValueError(f"ç»“æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {results_dir}")
    
    # æ”¶é›†æ‰€æœ‰ .txt æ–‡ä»¶ï¼ˆæŒ‰æ•°å­—æ’åºï¼‰
    txt_files = list(results_path.glob("*.txt"))
    txt_files.sort(key=lambda x: int(x.stem) if x.stem.isdigit() else 0)
    
    if not txt_files:
        raise ValueError(f"æœªæ‰¾åˆ°ä»»ä½• .txt æ–‡ä»¶åœ¨: {results_dir}")
    
    total = 0
    strict_correct = 0
    fuzzy_correct = 0
    details = []
    
    if verbose:
        print(f"ğŸ“ æ­£åœ¨è¯„ä¼°: {results_dir}")
        print(f"ğŸ“Š å‘ç° {len(txt_files)} ä¸ªç»“æœæ–‡ä»¶\n")
        print("=" * 100)
    
    for txt_file in txt_files:
        try:
            predicted, correct, original_passed = extract_answer_from_result_file(txt_file)
            
            if predicted is None or correct is None:
                if verbose:
                    print(f"âš ï¸  æ ·æœ¬ {txt_file.stem}: æ— æ³•æå–ç­”æ¡ˆï¼Œè·³è¿‡")
                continue
            
            total += 1
            
            # ä¸¥æ ¼åŒ¹é…ï¼ˆåŸå§‹è¯„ä¼°ï¼‰
            strict_match = original_passed
            if strict_match:
                strict_correct += 1
            
            # æ¨¡ç³ŠåŒ¹é…ï¼ˆå¿½ç•¥é¡ºåºï¼‰
            fuzzy_match = fuzzy_match_smiles(predicted, correct)
            if fuzzy_match:
                fuzzy_correct += 1
            
            # è®°å½•è¯¦ç»†ç»“æœ
            detail = {
                'sample_id': txt_file.stem,
                'predicted': predicted,
                'correct': correct,
                'strict_match': strict_match,
                'fuzzy_match': fuzzy_match,
                'improved': fuzzy_match and not strict_match  # æ¨¡ç³ŠåŒ¹é…çº æ­£çš„
            }
            details.append(detail)
            
            # æ‰“å°è¯¦ç»†ä¿¡æ¯
            if verbose:
                if fuzzy_match:
                    if strict_match:
                        status = "âœ“âœ“"  # ä¸¥æ ¼å’Œæ¨¡ç³Šéƒ½å¯¹
                    else:
                        status = "âœ“*"  # ä»…æ¨¡ç³ŠåŒ¹é…å¯¹ï¼ˆé¡ºåºä¸åŒï¼‰
                else:
                    status = "âœ—âœ—"  # éƒ½é”™
                
                print(f"{status} æ ·æœ¬ {txt_file.stem:>3}")
                print(f"  é¢„æµ‹: {predicted}")
                print(f"  çœŸå®: {correct}")
                
                if detail['improved']:
                    print(f"  ğŸ’¡ æ¨¡ç³ŠåŒ¹é…çº æ­£ï¼ˆååº”ç‰©é¡ºåºä¸åŒï¼‰")
                    print(f"  æ ‡å‡†åŒ–é¢„æµ‹: {normalize_smiles(predicted)}")
                    print(f"  æ ‡å‡†åŒ–çœŸå®: {normalize_smiles(correct)}")
                
                print()
        
        except Exception as e:
            if verbose:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {txt_file} æ—¶å‡ºé”™: {e}")
            continue
    
    # è®¡ç®—å‡†ç¡®ç‡
    strict_accuracy = strict_correct / total if total > 0 else 0
    fuzzy_accuracy = fuzzy_correct / total if total > 0 else 0
    improved_count = fuzzy_correct - strict_correct
    
    # æ±‡æ€»ç»“æœ
    summary = {
        'total': total,
        'strict_correct': strict_correct,
        'fuzzy_correct': fuzzy_correct,
        'strict_accuracy': strict_accuracy,
        'fuzzy_accuracy': fuzzy_accuracy,
        'improved_count': improved_count,
        'details': details
    }
    
    if verbose:
        print("=" * 100)
        print("\nğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»:\n")
        print(f"  æ€»æ ·æœ¬æ•°: {total}")
        print(f"  ä¸¥æ ¼åŒ¹é…æ­£ç¡®æ•°: {strict_correct}")
        print(f"  ä¸¥æ ¼åŒ¹é…å‡†ç¡®ç‡: {strict_accuracy:.2%}")
        print(f"\n  æ¨¡ç³ŠåŒ¹é…æ­£ç¡®æ•°: {fuzzy_correct}")
        print(f"  æ¨¡ç³ŠåŒ¹é…å‡†ç¡®ç‡: {fuzzy_accuracy:.2%}")
        print(f"\n  ğŸ’¡ æ¨¡ç³ŠåŒ¹é…é¢å¤–çº æ­£: {improved_count} ä¸ªæ ·æœ¬")
        print(f"  å‡†ç¡®ç‡æå‡: {(fuzzy_accuracy - strict_accuracy):.2%}")
        
        # æ‰“å°æ­£ç¡®çš„é¢˜å·åˆ—è¡¨
        strict_correct_ids = [d['sample_id'] for d in details if d['strict_match']]
        fuzzy_correct_ids = [d['sample_id'] for d in details if d['fuzzy_match']]
        improved_ids = [d['sample_id'] for d in details if d['improved']]
        
        print(f"\nğŸ“‹ æ­£ç¡®æ ·æœ¬åˆ—è¡¨:")
        print(f"  ä¸¥æ ¼åŒ¹é…æ­£ç¡®: {strict_correct_ids}")
        print(f"  æ¨¡ç³ŠåŒ¹é…æ­£ç¡®: {fuzzy_correct_ids}")
        if improved_ids:
            print(f"  ğŸ’¡ æ¨¡ç³ŠåŒ¹é…é¢å¤–çº æ­£: {improved_ids}")
    
    return summary


def save_evaluation_report(summary: Dict, output_path: str = None):
    """
    ä¿å­˜è¯„ä¼°æŠ¥å‘Šåˆ°æ–‡ä»¶
    
    Args:
        summary: evaluate_retro_results_fuzzy() è¿”å›çš„ç»“æœå­—å…¸
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º "evaluation_report.txt"
    """
    if output_path is None:
        output_path = "evaluation_report.txt"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("é€†åˆæˆç»“æœæ¨¡ç³ŠåŒ¹é…è¯„ä¼°æŠ¥å‘Š\n")
        f.write("=" * 100 + "\n\n")
        
        f.write("æ€»ä½“ç»Ÿè®¡:\n")
        f.write(f"  æ€»æ ·æœ¬æ•°: {summary['total']}\n")
        f.write(f"  ä¸¥æ ¼åŒ¹é…æ­£ç¡®æ•°: {summary['strict_correct']}\n")
        f.write(f"  ä¸¥æ ¼åŒ¹é…å‡†ç¡®ç‡: {summary['strict_accuracy']:.2%}\n")
        f.write(f"  æ¨¡ç³ŠåŒ¹é…æ­£ç¡®æ•°: {summary['fuzzy_correct']}\n")
        f.write(f"  æ¨¡ç³ŠåŒ¹é…å‡†ç¡®ç‡: {summary['fuzzy_accuracy']:.2%}\n")
        f.write(f"  é¢å¤–çº æ­£æ ·æœ¬æ•°: {summary['improved_count']}\n")
        f.write(f"  å‡†ç¡®ç‡æå‡: {(summary['fuzzy_accuracy'] - summary['strict_accuracy']):.2%}\n\n")
        
        # æ·»åŠ æ­£ç¡®æ ·æœ¬åˆ—è¡¨
        strict_correct_ids = [d['sample_id'] for d in summary['details'] if d['strict_match']]
        fuzzy_correct_ids = [d['sample_id'] for d in summary['details'] if d['fuzzy_match']]
        improved_ids = [d['sample_id'] for d in summary['details'] if d['improved']]
        
        f.write("æ­£ç¡®æ ·æœ¬åˆ—è¡¨:\n")
        f.write(f"  ä¸¥æ ¼åŒ¹é…æ­£ç¡® ({len(strict_correct_ids)} ä¸ª): {strict_correct_ids}\n")
        f.write(f"  æ¨¡ç³ŠåŒ¹é…æ­£ç¡® ({len(fuzzy_correct_ids)} ä¸ª): {fuzzy_correct_ids}\n")
        if improved_ids:
            f.write(f"  ğŸ’¡ æ¨¡ç³ŠåŒ¹é…é¢å¤–çº æ­£ ({len(improved_ids)} ä¸ª): {improved_ids}\n")
        f.write("\n")
        
        f.write("=" * 100 + "\n")
        f.write("è¯¦ç»†ç»“æœ:\n\n")
        
        for detail in summary['details']:
            status = "âœ“" if detail['fuzzy_match'] else "âœ—"
            f.write(f"{status} æ ·æœ¬ {detail['sample_id']}\n")
            f.write(f"  é¢„æµ‹: {detail['predicted']}\n")
            f.write(f"  çœŸå®: {detail['correct']}\n")
            f.write(f"  ä¸¥æ ¼åŒ¹é…: {detail['strict_match']}\n")
            f.write(f"  æ¨¡ç³ŠåŒ¹é…: {detail['fuzzy_match']}\n")
            
            if detail['improved']:
                f.write(f"  ğŸ’¡ æ¨¡ç³ŠåŒ¹é…çº æ­£ï¼ˆååº”ç‰©é¡ºåºä¸åŒï¼‰\n")
            
            f.write("\n")
    
    print(f"âœ… è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


# å‘½ä»¤è¡Œæ¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è¯„ä¼°é€†åˆæˆç»“æœï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰")
    parser.add_argument("results_dir", type=str, help="ç»“æœæ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚ results/llm_retro_claude")
    parser.add_argument("--quiet", action="store_true", help="é™é»˜æ¨¡å¼ï¼Œä¸æ‰“å°è¯¦ç»†ä¿¡æ¯")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # æ‰§è¡Œè¯„ä¼°
    summary = evaluate_retro_results_fuzzy(args.results_dir, verbose=not args.quiet)
    
    # ä¿å­˜æŠ¥å‘Š
    if args.output:
        save_evaluation_report(summary, args.output)
    else:
        # é»˜è®¤ä¿å­˜åˆ°ç»“æœæ–‡ä»¶å¤¹å†…
        results_path = Path(args.results_dir)
        output_path = results_path / "fuzzy_evaluation_report.txt"
        save_evaluation_report(summary, str(output_path))
